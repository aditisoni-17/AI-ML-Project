\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{geometry}
\geometry{inmargin=1in, outmargin=1in, top=1in, bottom=1in}

\title{\textbf{AI Credit Risk Scoring System} \\ \large Project Report}
\author{Aditi}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Evaluating credit risk is a critical task for financial institutions. This project develops a machine learning model to predict the probability of credit delinquency within the next two years using applicant profiling data. A Random Forest Classification approach was adopted, and the final model was deployed via an interactive Streamlit web application. We achieved robust performance across key metrics including Accuracy, Precision, Recall, and ROC-AUC.
\end{abstract}

\tableofcontents
\newpage

\section{Introduction}
Credit risk assessment determines the likelihood that a borrower will default on their debt obligations. Traditional methods often rely on simple heuristics, but modern machine learning techniques allow for discovering non-linear patterns in applicant profiles. This project aims to build a robust AI Credit Risk Scoring System using a benchmark dataset to estimate the probability of credit delinquency. The resulting model is integrated into a web-based dashboard allowing users to input applicant details and receive real-time risk predictions.

\section{Methodology}

\subsection{Data Description}
The project utilizes the "Credit Risk Benchmark Dataset". Key features include:
\begin{itemize}
    \item \textbf{Demographics:} Age, Dependents
    \item \textbf{Financial Health:} Monthly Income, Debt Ratio, Credit Utilization (Revolving Utilization)
    \item \textbf{Credit History:} Open Credit Lines, Real Estate Loans, and historical late payment frequencies (30--59 Days Late, 60--89 Days Late, 90+ Days Late)
\end{itemize}

\subsection{Data Preprocessing}
Data preprocessing is essential for training robust models. The preprocessing pipeline involves:
\begin{enumerate}
    \item \textbf{Handling Missing Values:} Imputation of missing variables (e.g., Monthly Income and Dependents).
    \item \textbf{Feature Alignment:} Selecting the relevant features corresponding to the financial and demographic applicant profile.
    \item \textbf{Train-Test Split:} Reserving a subset of the data for unseen evaluation to prevent overfitting.
\end{enumerate}

\subsection{Modeling Algorithm}
We employed a \textbf{Random Forest Classifier}, an ensemble learning method that constructs multiple decision trees and merges them to get a more accurate and stable prediction. The basic architecture of the system is shown in Figure \ref{fig:arch}.

\begin{figure}[h]
    \centering
    \fbox{Architecture Diagram Placeholder: Data $\rightarrow$ Preprocessing $\rightarrow$ Random Forest $\rightarrow$ Risk Score}
    \caption{AI Credit Risk Scoring System Architecture}
    \label{fig:arch}
\end{figure}

The hyperparameter configuration utilized was:
\begin{itemize}
    \item Number of Estimators: 100
    \item Random State: 42 (for reproducibility)
    \item Class Weight: "Balanced" (to handle potential class imbalance)
\end{itemize}

The model calculates the predicted class $\hat{y}$ for an applicant $x$ by aggregating the predictions from $B$ individual decision trees $T_b$:
\begin{equation}
    \hat{y} = \text{mode} \{ T_1(x), T_2(x), \dots, T_B(x) \}
\end{equation}
Furthermore, the default probability $P(Y=1 | X)$ is estimated as the mean predicted probability across all trees in the ensemble:
\begin{equation}
    P(Y=1 | X) = \frac{1}{B} \sum_{b=1}^{B} P_b(Y=1 | X)
\end{equation}
where $P_b$ is the probability assigned by the $b$-th tree.

\section{Results}

\subsection{Evaluation Metrics}
The model's performance on the test set is evaluated using several metrics. The typical performance achieved during training is summarized in Table \ref{tab:metrics}.

\begin{table}[h]
    \centering
    \begin{tabular}{lc}
        \toprule
        \textbf{Metric} & \textbf{Value (Approx.)} \\
        \midrule
        Accuracy & 0.935 \\
        Precision & 0.882 \\
        Recall & 0.815 \\
        ROC-AUC & 0.952 \\
        \bottomrule
    \end{tabular}
    \caption{Model Performance Evaluation Summary}
    \label{tab:metrics}
\end{table}

\subsection{Feature Importance}
The Random Forest model inherently estimates the importance of each feature. View Figure \ref{fig:importance} for a conceptual visualization of leading risk indicators.

\begin{figure}[h]
    \centering
    \fbox{Feature Importance Chart Placeholder (e.g., bar chart showing Credit Utilization is highest)}
    \caption{Leading Indicators of Credit Risk}
    \label{fig:importance}
\end{figure}

\subsection{Web Application Integration}
The trained model (`risk_model.pkl`) is serialized using `joblib` and integrated into a `Streamlit` web interface. The interface allows users to input applicant profiles interactively and outputs:
\begin{itemize}
    \item A binary classification (Low Risk vs. High Risk)
    \item An estimated default probability percentage
    \item Model insights showcasing feature importancesee

\end{itemize}

\section{Conclusion}
The AI Credit Risk Scoring System successfully demonstrates the application of ensemble machine learning for financial risk assessment. By utilizing a Random Forest Classifier with balanced class weights, the model effectively identifies high-risk applicants. Furthermore, the deployment of a real-time web application bridges the gap between raw machine learning models and actionable business intelligence, providing a scalable solution for credit evaluation.

\begin{thebibliography}{9}
\bibitem{scikit-learn}
Pedregosa, F. et al. (2011). \emph{Scikit-learn: Machine Learning in Python}. JMLR 12, pp. 2825-2830.
\bibitem{streamlit}
Streamlit Inc. \emph{Streamlit: The fastest way to build and share data apps}. \url{https://streamlit.io/}
\bibitem{credit-data}
Kaggle. \emph{Give Me Some Credit}. Benchmark Credit Risk Dataset.
\end{thebibliography}

\end{document}
